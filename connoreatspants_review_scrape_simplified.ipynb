{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de3494c",
   "metadata": {},
   "source": [
    "This is just a test run of some code to pull out the user review data for the user = \"ConnorEatsPants\", before trying to scale it up \n",
    "to the full data set. The webpage in question is:\n",
    "\n",
    "https://letterboxd.com/connoreatspants/\n",
    "\n",
    "Important Notes: Need to install selenium and webdriver for any of this to work.\n",
    "\n",
    "-Selenium: Just use [pip install selenium] in terminal\n",
    "\n",
    "-webdriver: Follow these docs\n",
    "\n",
    "https://github.com/SergeyPirogov/webdriver_manager\n",
    "\n",
    "Technically this is for a different package, but it supposedly makes life easier.\n",
    "\n",
    "My versions when running this code are:\n",
    "\n",
    "selenium.__version__ = 4.36.0\n",
    "\n",
    "The version does change the syntax for webdriver-manager a bit, but this is covered on the page.\n",
    "\n",
    "The general idea is to use selenium to run a virtual browswer of their webpage to get access to the information. \n",
    "After that, lxml runs through the xml tree to find the pieces of the webpage we're interested in. We then have to convert the info\n",
    "since it's of the form \"n .5star reviews\" and we only need n. After we do extract n, we just write it to a .csv file which marks \n",
    "according to the different rating scales.\n",
    "\n",
    "Credit: This code is just a modification of Data Science FilmMaker on medium.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c32e9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from lxml import html\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\") \n",
    "\n",
    "## These two just give headless browsing (= no browser actually pops up), which speeds things up. \n",
    "## Without them  my run times were often about 40s for each function call, whereas with them \n",
    "# it seems to drop to ~10 s per each function call\n",
    "\n",
    "browser = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options = chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff5a8a01-0447-4a0c-b3f4-5b5ce7e6a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviewers = ['connoreatspants']     \n",
    "\n",
    "## This is just set up this way so we can make a list of all of the reviewers separately, and then import it\n",
    "\n",
    "## TODO: Make a function which makes a list of the reviewers we want to use\n",
    "\n",
    "def reviewer_ratings():\n",
    "\n",
    "    # Open the virtual browser\n",
    "    browser = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options = chrome_options)\n",
    "\n",
    "    filename = 'connoreatspants_test.csv'\n",
    "    with open(filename, 'w+') as file_object:\n",
    "        file_object.write(\"User,.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5\\n\")\n",
    "\n",
    "\n",
    "    with open(filename, 'a') as file_object:\n",
    "\n",
    "        for g in range(len(reviewers)):\n",
    "\n",
    "            print(f\"Opening \" + reviewers[g] + \"'s page...\")\n",
    "            pagename = 'https://letterboxd.com/' + reviewers[g] + '/'\n",
    "            browser.get(pagename)\n",
    "            print(\"Getting innerHTML...\")\n",
    "            innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "            print(\"Creating tree...\")\n",
    "            tree = html.fromstring(innerHTML)\n",
    "        \n",
    "            # Grab the relevant data and put into lists\n",
    "            print(\"parsing...\")\n",
    "\n",
    "                ## This one is funky. Looking through the html, the best way to uniquely identify the different \n",
    "                ## reviews is just to specify the location of the bars on the page. The general formula seems to be \n",
    "                ## location(n stars) = \"width 17px; left: 2n-1*18 px\" or so\n",
    "\n",
    "            reviews_05 = tree.xpath('//li[@style=\"width: 17px; left: 0px\"]/a/@data-original-title')\n",
    "            reviews_1 = tree.xpath('//li[@style=\"width: 17px; left: 18px\"]/a/@data-original-title')     ## Note: Can copy .xml path in inspect element,\n",
    "            reviews_15 = tree.xpath('//li[@style=\"width: 17px; left: 36px\"]/a/@data-original-title')    ## but this seems to give faster run times???\n",
    "            reviews_2 = tree.xpath('//li[@style=\"width: 17px; left: 54px\"]/a/@data-original-title')  \n",
    "            reviews_25 = tree.xpath('//li[@style=\"width: 17px; left: 72px\"]/a/@data-original-title') \n",
    "            reviews_3 = tree.xpath('//li[@style=\"width: 17px; left: 90px\"]/a/@data-original-title')  \n",
    "            reviews_35 = tree.xpath('//li[@style=\"width: 17px; left: 108px\"]/a/@data-original-title')   \n",
    "            reviews_4 = tree.xpath('//li[@style=\"width: 17px; left: 126px\"]/a/@data-original-title')\n",
    "            reviews_45 = tree.xpath('//li[@style=\"width: 17px; left: 144px\"]/a/@data-original-title')  \n",
    "            reviews_5 = tree.xpath('//li[@style=\"width: 17px; left: 162px\"]/a/@data-original-title')\n",
    "            \n",
    "                ## At this point, the output is along the lines of ['<#> .5 star reviews'] so we want to extract the information of\n",
    "                ## n out of the string. \n",
    "                ## The general set up is to split the string along spaces, and pick out the first element so we recover the whole number. \n",
    "                ## E.g., '15 1star review'.split(\" \") -> [\"15\", \"1star\", \"review\"] -> '15'\n",
    "\n",
    "\n",
    "            print(\"Extracting Review Number...\")\n",
    "            sr05 = reviews_05[0].split(\" \")[0]          \n",
    "            sr1 = reviews_1[0].split(\" \")[0]\n",
    "            sr15 = reviews_15[0].split(\" \")[0]\n",
    "            sr2 = reviews_2[0].split(\" \")[0]\n",
    "            sr25 = reviews_25[0].split(\" \")[0]\n",
    "            sr3 = reviews_3[0].split(\" \")[0]\n",
    "            sr35 = reviews_35[0].split(\" \")[0]\n",
    "            sr4 = reviews_4[0].split(\" \")[0]\n",
    "            sr45 = reviews_45[0].split(\" \")[0]\n",
    "            sr5 = reviews_5[0].split(\" \")[0]\n",
    "\n",
    "            print(\"Writing to File...\")\n",
    "            file_object.write(reviewers[g]+\",\")\n",
    "            file_object.write(sr05+\",\"+sr1+\",\"+sr15+\",\"+sr2+\",\"+sr25+\",\"+sr3+\",\"+sr35+\",\"+sr4+\",\"+sr45+\",\"+sr5+\"\\n\")\n",
    "\n",
    "\n",
    "        print(f\"File {filename} written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9189ba5-5a9e-4d25-8a8e-1d53f4393904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening connoreatspants's page...\n",
      "Getting innerHTML...\n",
      "Creating tree...\n",
      "parsing...\n",
      "Extracting Review Number...\n",
      "Writing to File...\n",
      "File connoreatspants_test.csv written\n"
     ]
    }
   ],
   "source": [
    "reviewer_ratings() ## Run time seems very dependent on factors I don't understand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e4d75",
   "metadata": {},
   "source": [
    "Now I just want to test it out manually so I'll just read the file directly and check. We should get a .csv file of the form\n",
    "\n",
    "user     .5     1     2    ...\n",
    "\n",
    "connoreatspants   3   6   8   ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "617da96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User,.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5\n",
      "connoreatspants,3,6,8,11,8,19,29,34,19,23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"connoreatspants_test.csv\",\"r\") as filename:\n",
    "    print(filename.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca1132",
   "metadata": {},
   "source": [
    "Running the above code does verify this. What's left after this is to compile a list of reviewers we want to use for the data, and then \n",
    "run the above code to get their review data. Then we can start to do statistics on them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f311b31",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
